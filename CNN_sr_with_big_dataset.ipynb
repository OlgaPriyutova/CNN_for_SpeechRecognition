{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcne64q6A2ZR",
        "outputId": "b06867e3-289e-4565-85a1-e0fa63a4bdf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: librosa 0.10.1\n",
            "Uninstalling librosa-0.10.1:\n",
            "  Successfully uninstalled librosa-0.10.1\n",
            "Found existing installation: resampy 0.4.2\n",
            "Uninstalling resampy-0.4.2:\n",
            "  Successfully uninstalled resampy-0.4.2\n",
            "Found existing installation: numba 0.57.1\n",
            "Uninstalling numba-0.57.1:\n",
            "  Successfully uninstalled numba-0.57.1\n",
            "Collecting librosa\n",
            "  Using cached librosa-0.10.1-py3-none-any.whl (253 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Collecting numba>=0.51.0 (from librosa)\n",
            "  Using cached numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.7.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.40.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
            "Installing collected packages: numba, librosa\n",
            "Successfully installed librosa-0.10.1 numba-0.57.1\n",
            "Collecting resampy\n",
            "  Using cached resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.23.5)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.57.1)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.40.1)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.2\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y librosa resampy numba\n",
        "!pip install librosa\n",
        "!pip install resampy\n",
        "!pip install soundfile\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4guSGl9WA3C-",
        "outputId": "d3159efc-904d-49e2-96a1-09e1827cdd8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1610maeYBJ22"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import soundfile as sf\n",
        "\n",
        "\n",
        "\n",
        "# Define the path to the parent directory containing subfolders 0, 1, 2, ..., 9\n",
        "parent_path = '/content/drive/MyDrive/data/'\n",
        "\n",
        "\n",
        "#def load_audio_files(path):\n",
        "#    X, y = [], []\n",
        "#    for subdir in os.listdir(path):\n",
        "#        subdir_path = os.path.join(path, subdir)\n",
        "#        if os.path.isdir(subdir_path):\n",
        "#            for filename in os.listdir(subdir_path):\n",
        "#                if filename.endswith('.wav'):\n",
        "#                    audio, sr = sf.read(os.path.join(subdir_path, filename))\n",
        "#\n",
        "#                    # Continue extracting MFCCs and processing the audio as before...\n",
        "#                    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40).T, axis=0)\n",
        "#                    label = int(filename.split('_')[0])  # Extract digit label from filename\n",
        "#                    X.append(mfccs)\n",
        "#                    y.append(label)\n",
        "#    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def load_audio_files(path, max_length=66150):  # 66150 samples correspond to 1.5 seconds at 44.1kHz\n",
        "    X, y = [], []\n",
        "    for subdir in os.listdir(path):\n",
        "        subdir_path = os.path.join(path, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            for filename in os.listdir(subdir_path):\n",
        "                if filename.endswith('.wav'):\n",
        "                    audio, sr = sf.read(os.path.join(subdir_path, filename))\n",
        "\n",
        "                    # Ensure audio has the same length, either by truncating or zero-padding\n",
        "                    if len(audio) > max_length:\n",
        "                        audio = audio[:max_length]\n",
        "                    elif len(audio) < max_length:\n",
        "                        audio = np.pad(audio, (0, max_length - len(audio)))\n",
        "\n",
        "                    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40).T, axis=0)\n",
        "                    label = int(filename.split('_')[0])\n",
        "                    X.append(mfccs)\n",
        "                    y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "\n",
        "# Load audio files from subfolders\n",
        "X, y = load_audio_files(parent_path)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for CNN\n",
        "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
        "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train_cnn = to_categorical(y_train - 1, num_classes=9)\n",
        "y_test_cnn = to_categorical(y_test - 1, num_classes=9)\n",
        "\n",
        "# Create a CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(9, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_cnn, y_train_cnn, epochs=60, batch_size=32, validation_data=(X_test_cnn, y_test_cnn))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI-5uhxyA3LU",
        "outputId": "ce610ebe-c3ee-448a-8ea9-50b9c52cdf24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "125/125 [==============================] - 2s 8ms/step - loss: 4.3603 - accuracy: 0.2836 - val_loss: 1.3677 - val_accuracy: 0.5882\n",
            "Epoch 2/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.1919 - accuracy: 0.5596 - val_loss: 0.5497 - val_accuracy: 0.7876\n",
            "Epoch 3/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5875 - accuracy: 0.7723 - val_loss: 0.2428 - val_accuracy: 0.9248\n",
            "Epoch 4/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3942 - accuracy: 0.8560 - val_loss: 0.1762 - val_accuracy: 0.9399\n",
            "Epoch 5/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2937 - accuracy: 0.8930 - val_loss: 0.1518 - val_accuracy: 0.9489\n",
            "Epoch 6/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2261 - accuracy: 0.9163 - val_loss: 0.1135 - val_accuracy: 0.9609\n",
            "Epoch 7/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1938 - accuracy: 0.9321 - val_loss: 0.1295 - val_accuracy: 0.9579\n",
            "Epoch 8/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1663 - accuracy: 0.9386 - val_loss: 0.1025 - val_accuracy: 0.9609\n",
            "Epoch 9/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1481 - accuracy: 0.9446 - val_loss: 0.0816 - val_accuracy: 0.9739\n",
            "Epoch 10/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1379 - accuracy: 0.9517 - val_loss: 0.0905 - val_accuracy: 0.9659\n",
            "Epoch 11/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1077 - accuracy: 0.9652 - val_loss: 0.0711 - val_accuracy: 0.9719\n",
            "Epoch 12/60\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1054 - accuracy: 0.9622 - val_loss: 0.0631 - val_accuracy: 0.9780\n",
            "Epoch 13/60\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0892 - accuracy: 0.9679 - val_loss: 0.0757 - val_accuracy: 0.9749\n",
            "Epoch 14/60\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0896 - accuracy: 0.9709 - val_loss: 0.0623 - val_accuracy: 0.9820\n",
            "Epoch 15/60\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1016 - accuracy: 0.9639 - val_loss: 0.0708 - val_accuracy: 0.9729\n",
            "Epoch 16/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9749 - val_loss: 0.0675 - val_accuracy: 0.9770\n",
            "Epoch 17/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0728 - accuracy: 0.9742 - val_loss: 0.0574 - val_accuracy: 0.9810\n",
            "Epoch 18/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0679 - accuracy: 0.9742 - val_loss: 0.0645 - val_accuracy: 0.9800\n",
            "Epoch 19/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0593 - accuracy: 0.9782 - val_loss: 0.0595 - val_accuracy: 0.9800\n",
            "Epoch 20/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0727 - accuracy: 0.9727 - val_loss: 0.0544 - val_accuracy: 0.9820\n",
            "Epoch 21/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0561 - accuracy: 0.9827 - val_loss: 0.0560 - val_accuracy: 0.9820\n",
            "Epoch 22/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0639 - accuracy: 0.9802 - val_loss: 0.0488 - val_accuracy: 0.9850\n",
            "Epoch 23/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0555 - accuracy: 0.9792 - val_loss: 0.0534 - val_accuracy: 0.9790\n",
            "Epoch 24/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0582 - accuracy: 0.9787 - val_loss: 0.0468 - val_accuracy: 0.9870\n",
            "Epoch 25/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0530 - accuracy: 0.9840 - val_loss: 0.0457 - val_accuracy: 0.9850\n",
            "Epoch 26/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0613 - accuracy: 0.9795 - val_loss: 0.0638 - val_accuracy: 0.9719\n",
            "Epoch 27/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0551 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9860\n",
            "Epoch 28/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0433 - accuracy: 0.9850 - val_loss: 0.0480 - val_accuracy: 0.9840\n",
            "Epoch 29/60\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0563 - accuracy: 0.9795 - val_loss: 0.0380 - val_accuracy: 0.9880\n",
            "Epoch 30/60\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0463 - accuracy: 0.9847 - val_loss: 0.0475 - val_accuracy: 0.9840\n",
            "Epoch 31/60\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.0374 - val_accuracy: 0.9880\n",
            "Epoch 32/60\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.0294 - val_accuracy: 0.9900\n",
            "Epoch 33/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.0431 - val_accuracy: 0.9850\n",
            "Epoch 34/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0500 - accuracy: 0.9820 - val_loss: 0.0388 - val_accuracy: 0.9840\n",
            "Epoch 35/60\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.0332 - val_accuracy: 0.9880\n",
            "Epoch 36/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0469 - accuracy: 0.9822 - val_loss: 0.0411 - val_accuracy: 0.9870\n",
            "Epoch 37/60\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.0346 - val_accuracy: 0.9880\n",
            "Epoch 38/60\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9872 - val_loss: 0.0540 - val_accuracy: 0.9810\n",
            "Epoch 39/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0454 - accuracy: 0.9847 - val_loss: 0.0346 - val_accuracy: 0.9850\n",
            "Epoch 40/60\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.0304 - val_accuracy: 0.9880\n",
            "Epoch 41/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 0.0308 - val_accuracy: 0.9880\n",
            "Epoch 42/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 0.0403 - val_accuracy: 0.9880\n",
            "Epoch 43/60\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0283 - accuracy: 0.9885 - val_loss: 0.0425 - val_accuracy: 0.9850\n",
            "Epoch 44/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 0.0815 - val_accuracy: 0.9760\n",
            "Epoch 45/60\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9852 - val_loss: 0.0347 - val_accuracy: 0.9890\n",
            "Epoch 46/60\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0416 - accuracy: 0.9877 - val_loss: 0.0263 - val_accuracy: 0.9920\n",
            "Epoch 47/60\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 0.0323 - val_accuracy: 0.9890\n",
            "Epoch 48/60\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0615 - val_accuracy: 0.9850\n",
            "Epoch 49/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0331 - accuracy: 0.9872 - val_loss: 0.0429 - val_accuracy: 0.9820\n",
            "Epoch 50/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0324 - accuracy: 0.9860 - val_loss: 0.0461 - val_accuracy: 0.9840\n",
            "Epoch 51/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0386 - val_accuracy: 0.9870\n",
            "Epoch 52/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.0274 - val_accuracy: 0.9900\n",
            "Epoch 53/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 0.0409 - val_accuracy: 0.9880\n",
            "Epoch 54/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0423 - accuracy: 0.9855 - val_loss: 0.0312 - val_accuracy: 0.9870\n",
            "Epoch 55/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 0.0292 - val_accuracy: 0.9910\n",
            "Epoch 56/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9895 - val_loss: 0.0262 - val_accuracy: 0.9860\n",
            "Epoch 57/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0346 - accuracy: 0.9870 - val_loss: 0.0250 - val_accuracy: 0.9910\n",
            "Epoch 58/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
            "Epoch 59/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.0330 - val_accuracy: 0.9920\n",
            "Epoch 60/60\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.0411 - val_accuracy: 0.9880\n",
            "Test loss: 0.04109395295381546\n",
            "Test accuracy: 0.9879759550094604\n"
          ]
        }
      ]
    }
  ]
}